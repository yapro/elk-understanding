# https://www.elastic.co/guide/en/logstash/current/input-plugins.html
input {
    # при появлении строки в данном файле, она сразу будет вычетана и обработана самим logstash
    file {
         path => "/tmp/logstash-input.txt"
         type => "type_from_logstash_input"
         # codec => multiline {
         #         ...
         # }
         # tags => ["bbb"]
    }
    # logstash начинает прослушивать данных порт и при появлении строки сразу обработывается самим logstash
    # https://www.elastic.co/guide/en/logstash/current/plugins-inputs-beats.html#plugins-inputs-beats-type
    beats {
        host => "0.0.0.0"
        port => "31311"
        # если указать, то не json-строки не попадут в filter:
        # codec => "json"
    }
}
# https://www.elastic.co/guide/en/logstash/current/filter-plugins.html
filter {
    # в JSON лог-записе в поле message содержится json, поэтому берем значение из поле message, и расширяем его до фактической структуры json
    # см. таблицу преобразования в README.md файле
    # https://www.elastic.co/guide/en/logstash/6.8/plugins-filters-json.html
    # json {
    #    имя поля, в котором предположительно содержится json:
    #    source => "message"
    #    имя поля, которое будет содержать раздекоденный json из поля message (при этом поле message останется):
    #    target => "message_json"
    #    создаем поле id с значением my_filter:
    #    id => "my_filter"
    #    данная опция позволит игнорировать невалидное значение указанное в поле message:
    #    skip_on_invalid_json => true
    #}
    json {
        source => "message"
        target => "message_json"
        id => "my_filter"
        skip_on_invalid_json => true
        # remove_field => "message"
        # remove_field => [ "message" ]
        # add_tag => [ "_message_json_parsed" ]
    }
    # костыль для бага https://github.com/elastic/ecs/issues/35#issuecomment-803558801
    # input.file в json-объекте создает поле "host" => "8e4dcd8b2607" которое Elasticsearch ожидает увидеть в виде объекта, поэтому просто удаляю поле:
    mutate {
        remove_field => [ "host" ]
    }
    # help: https://www.elastic.co/guide/en/logstash/current/plugins-filters-mutate.html

    # type может быть любым (это вовсе не какой-то тип из определенного списка):
    if [type] == "type_from_logstash_input" {
        mutate {
            add_field => {"type_from_logstash_input" => "my value"}
        }
    }
    # type=json вовсе не тип по-умолчанию и может быть задан только в input (см. выше, но не в самой лог-записе):
    if [type] == "json" {
        # if не срабатывает, т.к. не объявлен типа json в input
        mutate {
            add_field => {"type_json" => "not using"}
        }
    }
}
output {
    # чтобы в логах просматривать json-лог-запись, которая будет отправлена в elasticsearch
    stdout { codec => rubydebug }
    file {
        path => ["/tmp/logstash-output.txt"]
    }
    # отправляем json-лог-запись в elasticsearch
    elasticsearch {
        hosts => "elasticsearch:9200"
        # необязательные:
        index => "my-logstash-index"
        # manage_template => false
        # index => "%{[@metadata][beat]}-%{+YYYY.MM.dd}"
        # document_type => "%{[@metadata][type]}"
    }
}
# input {
#   beats {
#     port => 5044
#     codec => "json"
#   }
# }
#filter {
#    json {
#        source => "message"
#        target => "tweet"
#    }
#    json detect - https://discuss.elastic.co/t/looking-for-a-way-to-detect-json/102263
#
#  if "_jsonparsefailure" not in [tags] {
#    mutate {
#      add_field => {
#               "type" => "%{[parsedJson][type]}"
#           "hostname" => "%{[parsedJson][host]}"
#          "timestamp" => "%{[parsedJson][timestamp]}"
#           "customer" => "%{[parsedJson][customer]}"
#               "role" => "%{[parsedJson][role]}"
#         "sourcefile" => "%{[parsedJson][sourcefile]}"
#        "log_message" => "%{[parsedJson][message]}"
#      }
#    }
#    if [type] == "trm-error" {
#      grok {
#          # Grok filters go here
#      }
#    }
#    mutate {
#      remove_field => ["parsedJson", "message"]
#    }
#  }
#}
# input {
#     gelf {
#         port => 12201
#         type => gelf
#         codec => "json"
#     }
# }
#        mutate {
#            add_field => {"the_type" => "%{type}"}
#        }
#        mutate {
#            add_field => {"the_type2" => "%type"}
#        }
#        mutate {
#            add_field => {"the_type3" => "[type]"}
#        }
#        mutate {
#            add_field => {"the_type4" => [type]}
#        }
#
#        if [type] == "json" {
#            json {
#                source => "message"
#                target => "message_json"
#            }
#            mutate {
#                add_field => {"zzz" => "xxx"}
#            }
#        }

# filter {
#     if [kubernetes][container][name] == "seo-php-fpm" and 'k8s' in [tags] {
#         json {
#             id => "filter_k8s_php_apps"
#             source => "message"
#         }
#     }
# }
# output {
#   if "_jsonparsefailure" in [tags] {
#     file {
#       path => "/var/log/logstash/jsonparsefailure.log"
#       codec => rubydebug
#     }
#   }
# }
#        if "_jsonparsefailure" not in [tags]  {
#            json {
#                source => "[pm2][message]"
#                target => "[pm2][data]"
#                remove_field => "[pm2][message]"
#                skip_on_invalid_json => true
#            }
#        }
